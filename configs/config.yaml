# ./configs/config.yaml

model:
  # paths
  whisper_path: "/path/to/whisper"
  llada_path: "/path/to/llada"
  ckpt: "" # if not "", load model from ckpt for training or evaluation

  # window-level Q-Former
  second_per_window: 0.333333
  second_stride: 0.333333

  # LoRA
  lora: True
  lora_rank: 8
  lora_alpha: 32
  lora_dropout: 0.1

  gen_len: 128
  prompt_template: "USER: {}\nASSISTANT:"
  task_prompt: "Transcribe the audio:"

datasets:
  train_ann_path: "/path/to/train_ann.json"
  valid_ann_path: "/path/to/valid_ann.json"
  test_ann_path: "/path/to/test_ann.json"

run:
  # log & settings
  amp: True
  seed: 42
  output_dir: "/path/to/output_dir"

  log_freq: 50
  epoch_based: False
  iters_per_epoch: 3000 # only used when epoch_based is False
  accum_grad_iters: 1
  batch_size_train: 4
  batch_size_eval: 4
  num_workers: 0

  # optimizer & scheduler
  optims:
    max_epoch: 120
    warmup_steps: 3000
    warmup_start_lr: 1e-6
    init_lr: 3e-5
    min_lr: 1e-5
    weight_decay: 0.05
    beta2: 0.999